#####Trimming, deduplicating, and quality filtering fastq files

#download zip file of Misha’s scripts (https://github.com/z0on/2bRAD_denovo) to desktop

#upload the following scripts to 2bRAD folder on SCC- downloaded on 1/18/2023
2bRAD_trim_launch_dedup.pl
trim2bRAD_2barcodes_dedup.pl

#get permission for scripts
chmod 777 scriptname

2bRAD_trim_launch_dedup.pl fastq > trims2

#open the “trims2” file
geany trims2

#add the following to make into a qsub, "trims.qsub" for job submission
#!/bin/bash -l
#$ -V # inherit the submission environment
#$ -cwd # start job in submission directory
#$ -N trims2 # job name, anything you want
#$ -l h_rt=24:00:00
#$ -M kscavo@bu.edu #your email notification
#$ -m be

#submit qsub
qsub trims2.qsub

# for reference-based analysis: trimming poor quality bases off ends:
>trimse2
for file in *.tr0; do echo "cutadapt -q 15,15 -m 25 -o ${file/.tr0/}.trim $file > ${file}_trimlog.txt" >> trimse2; done
         #this creates a file called trimse-open up the file to see all the commands to use cutadapt for each file.

# execute all commands in trimse file (serial or parallel using Launcher, if your system allows) 

#once the job is finished, merge together all log files created from trimming so that they are easier to look at
cat *.txt > Merged_trimlog_files.txt 

#all trimmed files have ending, .trim

#check to see of you have the right amount of trim files (should match the number of .tr0 files)
ls -l *.trim | wc -l

# Mapping new 2bRAD field sample files and the 2bRAD 2019 PDIV samples to the new PacBio PDIV reference (pdiv_genome_curated_host_draft.fa) 

# pdiv_genome_curated_host_draft.fa = Porites divaricata reference genome

# Build and index your reference 
# define your ref genome variables in your current directory
export GENOME_FASTA=pdiv_genome_curated_host_draft.fa


# create a qsub to build your reference
geany buildref_pdiv.qsub

# add this to buildref_pdiv qsub
#!/bin/bash -l
#$ -V # inherit the submission environment
#$ -cwd #start job in submission directory
#$ -N buildref_pdiv # job name, anything you want
#$ -l h_rt=24:00:00
#$ -M kscavo@bu.edu
#$ -m be

module load bowtie2

cd /projectnb/cnidaria/kscavo/2bRAD/Mapped_to_PDIVgen

bowtie2-build $GENOME_FASTA $GENOME_FASTA

# submit job
qsub buildref_pdiv.qsub

# once it's done, index your reference (quick one - didn't do a job)
module load samtools
samtools faidx $GENOME_FASTA

# mapping reads to reference 

# map with --local option, enables clipping of mismatching ends (guards against deletions near ends of RAD tags)

GENOME_FASTA=pdiv_genome_curated_host_draft.fa
# mapping with --local option, enables clipping of mismatching ends (guards against deletions near ends of RAD tags)
2bRAD_bowtie2_launch.pl '\.trim$' $GENOME_FASTA > maps_pdivgenome

# execute all commands written to maps...
geany maps_pdivgenome

# added this text to the top of 'maps' file, and saved as maps.qsub
#!/bin/bash -l
#$ -V # inherit the submission environment
#$ -cwd # start job in submission directory
#$ -N maps_pdivgenome # job name
#$ -l h_rt=24:00:00
#$ -M kscavo@bu.edu #your email notification
#$ -m be

#also add module load bowtie2 to qsub

#submit maps_pdivgenome as a job
qsub maps_pdivgenome.qsub

#makes .sam files for all your samples

ls *.sam > sams   #makes a text file with all .sam files so that you can count them in next command
cat sams | wc -l # number should match number of trim files

>alignmentRates
for F in `ls *trim`; do 
M=`grep -E '^[ATGCN]+$' $F | wc -l | grep -f - maps.e* -A 4 | tail -1 | perl -pe 's/maps\.e\d+-|% overall alignment rate//g'` ;
echo "$F.sam $M">>alignmentRates;
done

# next stage is compressing, sorting and indexing the SAM files, so they become BAM files:
module load samtools
>s2b
for file in *.sam; do
echo "samtools sort -O bam -o ${file/.sam/}.bam $file && samtools index ${file/.sam/}.bam">>s2b;
done

#This makes a file called "s2b" which has makes a list of commands to execute
    
# open s2b file
geany s2b

# added this text to the top of 's2b' file, and saved as s2b.qsub
#!/bin/bash -l
#$ -V # inherit the submission environment
#$ -cwd # start job in submission directory
#$ -N s2b_pdivgen # job name
#$ -l h_rt=24:00:00
#$ -M kscavo@bu.edu #your email notification
#$ -m be

# also add module load samtools to qsub

# submit s2b.qsub as a job
qsub s2b.qsub

# makes .bam files for all your samples

# check to see if you have .bam files for all samples
ls *bam | wc -l  # should be the same number as number of trim files

# BAM files are the input into various genotype calling / popgen programs, this is the main interim result of the analysis. Archive them.

# ---- Using ANGSD for identity by state ---- #
output name = myresult_pdiv_field_mang

FILTERS="-minMapQ 20 -dosnpstat 1 -doHWE 1 -minInd 157 -minMaf 0.05"
# 157 = 85% of samples (0.85 x 185)

TODO="-doMajorMinor 1 -doMaf 1 -doCounts 1 -makeMatrix 1 -doIBS 1 -doCov 1 -doGeno 8 -dobcf 1 -doPost 1 -doGlf 2"

angsd -b bams_field_mang -GL 1 $FILTERS $TODO -P 1 -out myresult_pdiv_field_mang

# number of snps= 6686

# import resulting IBS matrix (.ibsmat) into R and use the detect_clones.R script from https://github.com/z0on/2bRAD_denovo to identify clones based on hierarchical clustering



